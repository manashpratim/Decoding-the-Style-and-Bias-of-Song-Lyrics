{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open( \"weat.txt\", \"r\" ) \n",
    "file=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "raw_sentences = tokenizer.tokenize(file.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('swiki.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\chris\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "C:\\Users\\chris\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "C:\\Users\\chris\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:46: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "C:\\Users\\chris\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowers vs insects , pleasant vs unpleasant, d = 1.1881989597424407\n",
      "instruments vs weapons , pleasant vs unpleasant, d = 1.584070596605994\n",
      "european_american_names vs african_american_names , pleasant vs unpleasant, d = 0.528270527720072\n",
      "european_american_names vs african_american_names , pleasant vs unpleasant, d = 0.5909287487384915\n",
      "european_american_names vs african_american_names , pleasant vs unpleasant, d = 1.0540060120145525\n",
      "male_names vs female_names , career vs family, d = 1.8783954839506039\n",
      "math vs arts , male_terms vs female_terms, d = 1.5316899440400966\n",
      "science vs arts , male_terms vs female_terms, d = 1.5248018063425715\n",
      "mental_disease vs physical_disease , temporary vs permanent, d = 1.3971233302806072\n",
      "young_people_names vs old_people_names , pleasant vs unpleasant, d = 0.5193217760371736\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(raw_sentences)-30):\n",
    "    words=raw_sentences[i*4].split()\n",
    "    target_one = words[0][:-1]\n",
    "    target_one_words = words[1:]\n",
    "    words1=raw_sentences[i*4+1].split()\n",
    "    target_two = words1[0][:-1]\n",
    "    target_two_words = words1[1:]\n",
    "    words2=raw_sentences[i*4+2].split()\n",
    "    attribute_one = words2[0][:-1]\n",
    "    attribute_one_words = words2[1:]\n",
    "    words3 = raw_sentences[i*4+3].split()\n",
    "    attribute_two = words3[0][:-1]\n",
    "    attribute_two_words = words3[1:]\n",
    "    target_attribute(target_one,target_two, target_one_words, attribute_one,attribute_two, attribute_one_words, target_two_words, attribute_two_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_attribute(target_one,target_two, target_one_words, attribute_one,attribute_two, attribute_one_words, target_two_words, attribute_two_words):\n",
    "    cos=[]\n",
    "    s=0\n",
    "    s1=[]\n",
    "    s2=[]\n",
    "    S=[]\n",
    "    n=0\n",
    "    for i in range(0, len(target_one_words)):\n",
    "            c1=[]\n",
    "            c2=[]\n",
    "            for k in range(0, len(attribute_one_words)):\n",
    "                wt = target_one_words[i][:-1]\n",
    "                at1 = attribute_one_words[k][:-1]\n",
    "                try:\n",
    "                    cos1= model.similarity(wt, at1)\n",
    "                    cos.append(cos1)\n",
    "                    c1.append(cos1)\n",
    "                except:\n",
    "                    cos1=0\n",
    "                    cos.append(cos1)\n",
    "                    c1.append(cos1)\n",
    "                    continue\n",
    "            for k in range(0, len(attribute_two_words)):\n",
    "                cos2=0\n",
    "                wt = target_one_words[i][:-1]\n",
    "                at2 = attribute_two_words[k][:-1]\n",
    "                try:\n",
    "                    cos2= model.similarity(wt, at2)\n",
    "                    cos.append(cos2)\n",
    "                    c2.append(cos2)\n",
    "                except:\n",
    "                    cos2=0\n",
    "                    cos.append(cos2)\n",
    "                    c2.append(cos2)\n",
    "                    continue\n",
    "            s1.append((np.mean(c1)-np.mean(c2)))\n",
    "            S.append((np.mean(c1)-np.mean(c2)))\n",
    "            n=n+1\n",
    "    for i in range(0, len(target_two_words)):\n",
    "            c1=[]\n",
    "            c2=[]\n",
    "            for k in range(0, len(attribute_one_words)):\n",
    "                wt = target_two_words[i][:-1]\n",
    "                at1 = attribute_one_words[k][:-1]\n",
    "                try:\n",
    "                    cos1= model.similarity(wt, at1)\n",
    "                    cos.append(cos1)\n",
    "                    c1.append(cos1)\n",
    "                except:\n",
    "                    cos1=0\n",
    "                    cos.append(cos1)\n",
    "                    c1.append(cos1)\n",
    "                    continue\n",
    "            for k in range(0, len(attribute_two_words)):\n",
    "                cos2=0\n",
    "                wt = target_two_words[i][:-1]\n",
    "                at2 = attribute_two_words[k][:-1]\n",
    "                try:\n",
    "                    cos2= model.similarity(wt, at2)\n",
    "                    cos.append(cos2)\n",
    "                    c2.append(cos2)\n",
    "                except:\n",
    "                    cos2=0\n",
    "                    cos.append(cos2)\n",
    "                    c2.append(cos2)\n",
    "                    continue\n",
    "            s2.append((np.mean(c1)-np.mean(c2)))\n",
    "            S.append((np.mean(c1)-np.mean(c2)))\n",
    "    s=np.sum(s1)-np.sum(s2)\n",
    "    stdev=np.std(S)\n",
    "    print(target_one + ' vs ' + target_two  + ' , ' +attribute_one + ' vs ' + attribute_two +', d = ' + str(s/(stdev*n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
